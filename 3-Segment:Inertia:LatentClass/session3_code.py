'''Foundation of Advanced Quantitative MarketingSeesion 3:     1) Observable heterogeneity models    2) State-dependence models    3) Latent class logit model.Data: Yogurt_Data.csvAuthor: Jingpeng HongInstructor: Pradeep Chintagunta'''#################### Housekeeping ####################import osimport csvimport pandas as pdimport numpy as npimport scipy as spfrom statsmodels.discrete.conditional_models import ConditionalLogit as clfrom statsmodels.iolib.summary2 import summary_colfrom sklearn.preprocessing import PolynomialFeaturesos.chdir("/Users/hongjingpeng/Desktop/Quant_Mkt/Advanced-Quantitative-Marketing-2022W/3-Segment:Inertia:LatentClass/")###################### Preparing Data ######################## load original data ##df = pd.read_csv("Data/Yogurt_Data.csv", usecols=range(19))## reshape data from wide to long ##df.rename(columns = {'Brand  2': 'Brand 2'}, inplace = True)colname = df.columns.tolist()df2 = pd.wide_to_long(df, stubnames=["Brand", "Feature", "Price"], i=colname[0:6], j="brand", sep=" ")df2 = df2.reset_index()df2.rename(columns = {'Brand': 'choice'}, inplace = True)############################# Observed Heterogenity ################################################# Median Split ###################### construct household characteristic data framedf_hh = df[['Pan I.D.', 'Income', 'HH Size']].drop_duplicates().reset_index()del df_hh['index']## median splitmed_size, med_income = df_hh[['HH Size', 'Income']].median()df2['upper_size'] = df2['HH Size'] > med_sizedf2['upper_income'] = df2['Income'] > med_incomedf2.loc[(df2['upper_size'] == True) & (df2['upper_income'] == True), 'group'] = 1df2.loc[(df2['upper_size'] == True) & (df2['upper_income'] == False), 'group'] = 2df2.loc[(df2['upper_size'] == False) & (df2['upper_income'] == True), 'group'] = 3df2.loc[(df2['upper_size'] == False) & (df2['upper_income'] == False), 'group'] = 4## brand dummybrand_dummy = pd.get_dummies(df2['brand'], prefix='brand')df2 = pd.concat([df2, brand_dummy], axis=1)## conditional logit estimation nJ = df2['brand'].nunique() # number of choicesest_list = []for i in range(1, 5):    df_sg = df2.loc[df2['group'] == i, ]    x = df_sg[['brand_1', 'brand_2', 'brand_3', 'Price', 'Feature']]    nN = int(len(df_sg)/nJ) # number of households    t = np.tile(np.arange(nN), nJ).reshape((nJ, nN)).T # purchase occasion group    est = cl(endog = df_sg.choice.to_numpy(),                 exog = x.to_numpy(),                 groups = t.reshape(-1)).fit()    est_list.append(est)res = summary_col([est_list[0],est_list[1], est_list[2], est_list[3]])res.tables[0].to_csv("output/seglogit.csv")#################################### Demographics as Interactions ###################################### generate interaction termsinter_brand = []brand_x = [df2['brand_1'], df2['brand_2'], df2['brand_3'],            df2['Price'], df2['Feature']]for x in brand_x:    inter1 = x * df2['Income']    inter_brand.append(inter1)    inter2 = x * df2['HH Size']    inter_brand.append(inter2)inter_brand = pd.DataFrame(inter_brand).Tinter_brand.columns = ['I1', 'HH1', 'I2', 'HH2', 'I3', 'HH3',                       'Ip', 'HHp', 'If', 'HHf']df2 = pd.concat([df2, inter_brand], axis=1)## model estimationx = df2[['brand_1', 'brand_2', 'brand_3', 'Price', 'Feature',         'Ip', 'HHp', 'If', 'HHf']]nN = int(len(df2)/nJ) # number of householdst = np.tile(np.arange(nN), nJ).reshape((nJ, nN)).T # purchase occasion groupest = cl(endog = df2.choice.to_numpy(),          exog = x.to_numpy(),          groups = t.reshape(-1)).fit()summary_col(est).tables[0].to_csv("output/interaction_logit.csv")